---
title: "Lesson 10 Poisson regression"
author: "Chun Hsien Wu"
date: "2021年6月28日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Lesson 10.2
#### Data
For an example of Poisson regression, we’ll use the `badhealth` data set from the `COUNT` package in `R`.

```{r}
library("COUNT")
```

```{r}
data("badhealth")
head(badhealth)
```
It's also a good idea to check. To make sure we don't have any missing values. We are going to check using `is.na`, which will flag missing values, and we want to see if there any of those.
```{r}
any(is.na(badhealth))
```
```{r}
plot(jitter(log(numvisit)) ~ jitter(age), data=badhealth, subset=badh==0, xlab="age", ylab="log(visits)")
points(jitter(log(numvisit)) ~ jitter(age), data=badhealth, subset=badh==1,  col="red")
```

#### Model
```{r}
library("rjags")
```
```{r}
mod_string = " model {
    for (i in 1:length(numvisit)) {
        numvisit[i] ~ dpois(lam[i])
        log(lam[i]) = int + b_badh*badh[i] + b_age*age[i] + b_intx*age[i]*badh[i]
    }
    
    int ~ dnorm(0.0, 1.0/1e6)
    b_badh ~ dnorm(0.0, 1.0/1e4)
    b_age ~ dnorm(0.0, 1.0/1e4)
    b_intx ~ dnorm(0.0, 1.0/1e4)
} "

set.seed(102)

data_jags = as.list(badhealth)

params = c("int", "b_badh", "b_age", "b_intx")

mod = jags.model(textConnection(mod_string), data=data_jags, n.chains=3)
update(mod, 1e3)

mod_sim = coda.samples(model=mod,
                        variable.names=params,
                        n.iter=5e3)
mod_csim = as.mcmc(do.call(rbind, mod_sim))
```
## convergence diagnostics
plot(mod_sim)
```{r}
gelman.diag(mod_sim)
autocorr.diag(mod_sim)
autocorr.plot(mod_sim)
effectiveSize(mod_sim)
```
compute DIC
```{r}
dic = dic.samples(mod, n.iter=1e3)
```
####Residuals
```{r}
X = as.matrix(badhealth[,-1])
X = cbind(X, with(badhealth, badh*age))

pmed_coef = apply(mod_csim, 2, median)
```
We want to use median here because we're going to be taking the inverse log or the exponential function of these point estimates.
And of course we'll matrix multiply these to get our predictions. First we will extract the log of lambda hat which will be our intercept first.
```{r}
llam_hat = pmed_coef["int"] + X %*% pmed_coef[c("b_badh", "b_age", "b_intx")]
```
This evaluated the linear part of the model for the observations. But to get back the original lambdas, or the means of that Poisson distribution, we have to take the inverse of the link function. So, lam_hat will be exponentialted version of the log lam_hat.
```{r}
lam_hat = exp(llam_hat)
```
Finally, we can calculate the residuals from the predictions. Resids will come from badhealth$numvisit.And we'll subtract off the predictions.
```{r}
resid = badhealth$numvisit - lam_hat
plot(resid)
```
Ordinarily we would be alarmed by this plot. The index of the data seems to have something to do, with the value of the residual which would suggest that the data are not independent. It turns out in this case that the data were presorted.

They were ordered by the number of doctor visits. Next, let's plot the predicted values against the residuals. Where we want to standrize the x-axis.

And let's look at each group one at a time. First, we want to look at the ones that have bad health. So, we'll take only the predictions where badhealth, badh==0, and we also want only those residuals as well.
which bad health in the original data set is 0.

Next, on top of that plot, we will add points, Where badhealth is 1. So, the lambda hats for which the badhealth indicator is 1. And the residuals for which the badhealth indicator is 1, and change color of these points.

And we also need ot add a y lim for these because the two groups have different range. So let's set the entire range of the residuals for our y-axis, now let's run this plot.
```{r}
plot(lam_hat[which(badhealth$badh==0)], resid[which(badhealth$badh==0)], xlim=c(0,8), ylim=range(resid))
points(lam_hat[which(badhealth$badh==1)], resid[which(badhealth$badh==1)], col="red")
```
On the x-axis we have lambda hat, the predicted mean of the Poisson. And on the y-axis we have the residual value. Intersetingly, the model separated the predicted number of visits according to whether or not the person had bad health.

If the person had bad health, the model predicts they'll have about six visits. And If they don't have bad health, the model predicts about two visits. It looks like this model isn't performing great. We have a lot of values here with really large residuals.

In other words, the number of visits was much higher than the model predicted for a lot of these people. # It's not surprising to see that the variability increases. A lam_hat increases. We're using a Poisson likelihood. And remember that in the Poisoon distribution, the mean and the variance are the same number. However, if the Poisson model is correct, this group of residuals should have variance about 2. And this group(with badhealth ==1) of residuals should have variance about six.

Let's test that. First, let's take the residuals for which badhealth is 0. And we'll calculate the variance of these residuals. We expect it was 
about two. Turn out it's about 7. Now, let's do the same thing for patientes were badhealth equals 1. We would expect the variance here to be about six. It turns out the variance is about 41. The fact that we observed so much more variability than we expected indicated that either the model is fits poorly. Meaning that the covariance don't explain enough of the variability in the data. Or the data are over dispersed for this Poisson likelihood  that we've chosen. This is a common issue with count data. If the data are more variable than Poisson likelihood suggest, we can look to alternatvie models for over dispersed data. One common alternative is to use the negative binomial distribution.
```{r}
var( resid[which(badhealth$badh==0)])
var( resid[which(badhealth$badh==1)])
summary(mod_sim)
```
Healthy person is  person1 at badhealth =0, at age = 35, interaction = 0, 
and unhealth person is person2 at badhealth =1, at age = 35, interaction = 35
```{r}
x1 = c(0,35,0)
x2 = c(1,35,35)
```
Remember that all the posterior samples for the model parameters are stored in  mod_csim. For these two individuals, we need to compute the linear part of the predictor.
```{r}
head(mod_csim)
loglam1 = mod_csim[, "int"] + mod_csim[ , c(2, 1, 3)] %*% x1
loglam2 = mod_csim[, "int"] + mod_csim[ , c(2, 1, 3)] %*% x2
```
We run both of these, and this gives us a Monte Carlo sample of the linear part of the model. So we have one for each sample from the posterior

Now that we have samples from the posterior distribution of the log lambda for these individuals, we need to get the posterior distribution of lambda. So we'll say lam1 will be an exponentiated version of log lambda 1. And we'll do the same for person two. We now have Monte Carlo samples for the Poisson mean for these two individuals. 
```{r}
lam1 = exp(loglam1)
lam2 = exp(loglam2)
```
Take a look at the posterior distribution for lambda1 for person 1.
```{r}
plot(density(lam1))
```
```{r}
n_sim = length(lam1)
```

First we want to plot for person 1, we want to plot table of y1 as a factor variable. So we need to say factor(y1) and, let's plot this for up to 18 visits. We want this table to output probabilityes instead of counts, so let's devide by number of simulations.

Let' run this plot. So along the x-axis we have the number of doctor
```{r}
y1 = rpois(n_sim, lam1)
y2 = rpois(n_sim, lam2)
plot(table(factor(y1, levels= 0: 18))/ n_sim)
points(table((y2 + 0.1))/ n_sim, col ="red")
```

Finally, we can answer our original question. What's the probability that the person with poor health will have more doctor visits than the person with good health. We can take the Monte Carlo mean of that indicator variable, 
```{r}
mean(y2 > y1)
```



