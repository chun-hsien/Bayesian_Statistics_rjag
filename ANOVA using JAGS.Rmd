---
title: "ANOVA using JAGS"
author: "Chun Hsien Wu"
date: "2021年6月12日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### One way anova example
#### Data
```{r}
data("PlantGrowth")
head(PlantGrowth)
```
Because the explanatory variable group is a factor and not continuous, we choose to visualized the data with the data with box plots rather than scatter plots.

```{r}
boxplot(weight ~ group, data = PlantGrowth)
```

#### Modeling
We can start with the reference analysis(with a noninformative prior) with a linear model in `R`
```{r}
lmod = lm(weight ~ group, data = PlantGrowth)
summary(lmod)
```
```{r}
anova(lmod)
```
Now, let's use JAGS to fit themodel
```{r}
library("rjags")

mod_string = " model {
	for (i in 1:length(y)) {
		y[i] ~ dnorm(mu[grp[i]], prec)
    	}
    
    	for (j in 1:3) {
        	mu[j] ~ dnorm(0.0, 1.0/1.0e6)
    	}
    
   	prec ~ dgamma(5/2.0, 5*1.0/2.0)
	sig = sqrt( 1.0 / prec )
} "

data_jags = list(y=PlantGrowth$weight, 
				grp=as.numeric(PlantGrowth$group))

params = c("mu", "sig")

inits = function() {
    inits = list("mu"=rnorm(3,0.0,100.0), "prec"=rgamma(1,1.0,1.0))
}

mod = jags.model(textConnection(mod_string), data=data_jags, inits=inits, n.chains=3)

# run 1000 iterations as burn in 
update(mod, 1e3)

# run 3 chains for 5000 iterations to save those samples, and combining the samples in the end.
mod_sim = coda.samples(model=mod,
                        variable.names=params,
                        n.iter=5e3)
# combined chains
mod_csim = as.mcmc(do.call(rbind, mod_sim))
```
#### Model Checking
Before we check the inferences from the model, we should perform convergence diagnostics for our Markov chains.
```{r}
plot(mod_sim)

gelman.diag(mod_sim)
autocorr.diag(mod_sim)
effectiveSize(mod_sim) 
```
Let's calculate the posterior mean for the parameters
```{r}
(pm_params = colMeans(mod_csim))
```
We can also look at the residuals to see if there are any obvious problems with our model choice.

Let's use these posterior means of the parameters to compute residuals. The first thing we need are predictions for 
each observations, call that yhat. And it'll be based on the posterior means for these parameters for the first three means.

Let's compare those to the coefficients estimate that we got from the non-informative reference analysis.
```{r}
coefficients(lmod)
```
These results look pretty consistent. 
THe mu estimates for the control group are similar between the two models.

And we want to index these by their group indicator. So that comes from datajags the group variable.

We can calculate the residuals as the differences between the data and the predictive values.
Let's plot the residuals against their index or observation number and we don't see any patterns, That's pretty good.
```{r}
yhat = pm_params[1:3][data_jags$grp]
resid = data_jags$y - yhat
plot(resid)
```
Next, Let's create a residual plot, where the x-axis contains the predicted values.

```{r}
plot(yhat, resid)
```
# Not surprisingly, there are only three sets of predictions because there are three groups. But one thing that really stands out is that the variance for this group, the residual variance, is much higher than the residual variance for this group. As we mentioned earlier,  it might be appropriate to have a separate variance parameter for each group, just like we had a separate mu parameter for each group. The author leaves it as exercise.

Let's now look at the summary of the posterior distributions.
```{r}
summary(mod_sim)
```
If we want to create the hightest posterior density interval, an HPD

```{r}
HPDinterval(mod_csim)
```
Let's run that, and get a 95% HPDinterval for each of the parameters. Usually the HPDinterval is slightly smaller than the interval using equal tails. We can also give it another argument. 

If we want to change the posterior probability associated with the interval, we can change it to, for example, .9, and we would get 90% posterior probability intervals.

Now, suppose that in this experiment we are interested should know if one of the treatments increases the mean yield from the plants. It's clear from the posterior summary that treatment 1 does not increase, plant yield over the control group. But treatment 2 might increase. One major advantage of having a Bayesian model with Monte Carlo samples from the posterior is that it is easy to calculate posterior probabilities of hypothesis like this.


So if we want to find out whether treatment 2 produces a larger yield than the control group, let's create an indicator variable. From our combined simulations Columns3 regers to mu 3. We want to see if mu 3 is bigger than mu 1. We take the average of that, that gives us the posterior probability, the codes is below: 
```{r}
mean(mod_csim[,3] > mod_csim[,1])
```
A very high posterior probability that the mean yield is greater for treatment in group two than the control group.

Now suppose that treatment 2 would be costly to put into production and in order to be worthwhile.
 
This treatment must increase the mean yield by at least 10%. What is the posterior probability that the increase is at least that?

Well, we can easily do this with posterior samples again and we need mu 3 to be at least 10% larger than mu1, below is the codes
```{r}
mean(mod_csim[,3] > 1.1 * mod_csim[,1])
```

The posterior probability for this hypothesis is about 0.48.

